{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac",
      "metadata": {
        "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac"
      },
      "source": [
        "# Assignment #4: Linear Models and Decision Trees\n",
        "## Foundations of Machine Learning\n",
        "## Do Q1 and one other question.\n",
        "### Advice: Reuse your code and code from lectures, package routine tasks into functions, make plans about how you'll carry out the analysis before jumping into writing code, and work as efficiently as possible"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b",
      "metadata": {
        "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b"
      },
      "source": [
        "**Q1.** This question is a case study for linear models and decision trees. The data are about car prices. In particular, they include:\n",
        "\n",
        "  - `Price`, `Color`, `Seating_Capacity`\n",
        "  - `Body_Type`: crossover, hatchback, muv, sedan, suv\n",
        "  - `Make`, `Make_Year`: The brand of car and year produced\n",
        "  - `Mileage_Run`: The number of miles on the odometer\n",
        "  - `Fuel_Type`: Diesel or gasoline/petrol\n",
        "  - `Transmission`, `Transmission_Type`:  speeds and automatic/manual\n",
        "\n",
        "  1. Load `cars_hw.csv`. These data were really dirty, and I've already cleaned them a significant amount in terms of missing values and other issues, but some issues remain (e.g. outliers, badly scaled variables that require a log or arcsinh transformation). Clean the data however you think is most appropriate.\n",
        "  2. Summarize the `Price` variable and create a kernel density plot. Use `.groupby()` and `.describe()` to summarize prices by brand (`Make`). Make a grouped kernel density plot by `Make`. Which car brands are the most expensive? What do prices look like in general?\n",
        "  3. Split the data into an 80% training set and a 20% testing set.\n",
        "  4. Let's focus on linear models. Make a model where you regress price on the numeric variables alone; what is the $R^2$ and `RMSE` on the test set? Make a second model where, for the categorical variables, make a model comprised of one-hot encoded regressors/features alone, and regress price on those variables; what is the $R^2$ and `RMSE` on the test set? Which model performs better on the test set? Make a third model that combines all the regressors from the previous two; what is the $R^2$ and `RMSE` on the test set? Does the joint model perform better or worse, and by home much?\n",
        "  5. Use the `PolynomialFeatures` function from `sklearn` to expand the set of numerical variables you're using, along with the categorical variables. As you increase the degree of the expansion, how do the $R^2$ and `RMSE` change? At what point does $R^2$ go negative on the test set? For your best model with expanded features, what is the $R^2$ and `RMSE`? How does it compare to your best model from part 3?\n",
        "  6. For your best model so far, determine the predicted values for the test data and plot them against the true values. Do the predicted values and true values roughly line up along the diagonal, or not? Compute the residuals/errors for the test data and create a kernel density plot. Do the residuals look roughly bell-shaped around zero? Evaluate the strengths and weaknesses of your model.\n",
        "  7. Now, let's use a regression tree. Construct an appropriate matrix of regressors/features, and fit a tree to the data. Vary the maximum depth of the decision tree using the `max_depth` option (i.e. `tree.DecisionTreeRegressor(max_depth=D)`), and compute the $R^2$ and `RMSE` on the test set of a variety of depths. What depth tree gives the best results?\n",
        "  8. For your best tree, determine the predicted values for the test data, and plot them against the true values. Do the predicted values and true values line up along the diagonal, or not? Compute the residuals/errors for the test data and create a kernel density plot. Do the residuals look roughly bell-shaped around zero?\n",
        "  12. Which model --- linear model or classification and regression tree --- has better performance on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://www.github.com/DS3001/assignment4\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def pn(x):\n",
        "  print(x,'\\n')\n",
        "  return\n",
        "\n",
        "#1 - data loading and cleaning\n",
        "\n",
        "cdf = pd.read_csv('./assignment4/data/cars_hw.csv')\n",
        "\n",
        "print(cdf.head())\n",
        "print(cdf.shape) #look at dimensions\n",
        "print(cdf.columns.tolist()) #summarize variables\n",
        "print(cdf.dtypes) #summarize variable datatypes\n",
        "\n",
        "#sns.scatterplot(data=cdf,y='Price',x='Make') # definitely some outliers but I'm not sure I want to get rid of them - instead will rescale price using logs\n",
        "\n",
        "# Take arcsinh transformation to rescale the variables\n",
        "cdf['price_log'] = np.arcsinh(cdf['Price'])\n",
        "#cdf['age_ihs'] = np.arcsinh(cdf['age'])\n",
        "#sns.scatterplot(data=cdf,y='price_log',x='Make') # I can't tell a huge difference between this scatterplot and the previous one\n",
        "\n",
        "cdf['price_log'].hist(bins=20) # this looks better in terms of outliers and scale"
      ],
      "metadata": {
        "id": "I0N9qUl2h7KA",
        "outputId": "e7d04660-900b-4952-abdf-7dd720937454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "I0N9qUl2h7KA",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'assignment4' already exists and is not an empty directory.\n",
            "   Unnamed: 0        Make  Make_Year   Color  Body_Type  Mileage_Run  \\\n",
            "0           1  Volkswagen       2017  silver      sedan        44611   \n",
            "1           2     Hyundai       2016     red  crossover        20305   \n",
            "2           3       Honda       2019   white        suv        29540   \n",
            "3           4     Renault       2017  bronze  hatchback        35680   \n",
            "4           5     Hyundai       2017  orange  hatchback        25126   \n",
            "\n",
            "  No_of_Owners  Seating_Capacity Fuel_Type Transmission Transmission_Type  \\\n",
            "0          1st                 5    diesel      7-Speed         Automatic   \n",
            "1          1st                 5    petrol      5-Speed            Manual   \n",
            "2          2nd                 5    petrol      5-Speed            Manual   \n",
            "3          1st                 5    petrol      5-Speed            Manual   \n",
            "4          1st                 5    petrol      5-Speed            Manual   \n",
            "\n",
            "    Price  \n",
            "0  657000  \n",
            "1  682000  \n",
            "2  793000  \n",
            "3  414000  \n",
            "4  515000  \n",
            "(976, 12)\n",
            "['Unnamed: 0', 'Make', 'Make_Year', 'Color', 'Body_Type', 'Mileage_Run', 'No_of_Owners', 'Seating_Capacity', 'Fuel_Type', 'Transmission', 'Transmission_Type', 'Price']\n",
            "Unnamed: 0            int64\n",
            "Make                 object\n",
            "Make_Year             int64\n",
            "Color                object\n",
            "Body_Type            object\n",
            "Mileage_Run           int64\n",
            "No_of_Owners         object\n",
            "Seating_Capacity      int64\n",
            "Fuel_Type            object\n",
            "Transmission         object\n",
            "Transmission_Type    object\n",
            "Price                 int64\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 Summarize the Price variable and create a kernel density plot.\n",
        "#Use .groupby() and .describe() to summarize prices by brand (Make).\n",
        "#Make a grouped kernel density plot by Make.\n",
        "#Which car brands are the most expensive? What do prices look like in general?\n",
        "\n",
        "#summarizing Price (log version) variable\n",
        "print(cdf['price_log'].unique(),'\\n')\n",
        "print(cdf.dtypes)\n",
        "cdf['price_log'] = pd.to_numeric(cdf['price_log']) # it's already numeric I'm not sure why I did this\n",
        "cdf['price_log'].hist(bins=20)\n",
        "range_value = max(cdf['price_log']) - min(cdf['price_log']) # small difference in range\n",
        "print(range_value)"
      ],
      "metadata": {
        "id": "pNNU40EMmSWN",
        "outputId": "e9f2532f-ee9b-4d5a-dec1-8f7658fdb490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "pNNU40EMmSWN",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14.08858648 14.12593212 14.27672568 13.62676843 13.84506936 14.00447666\n",
            " 13.35664467 14.85861014 14.16616743 13.5721643  14.0192674  13.99449321\n",
            " 14.47716707 15.25059508 14.10219213 14.54691645 14.35550656 14.35783485\n",
            " 14.12299526 14.03865411 13.94126176 13.51710452 14.5819082  13.97592728\n",
            " 13.58231667 13.91806715 14.49252836 13.82941346 13.97422225 14.06080691\n",
            " 13.0689626  13.88503662 13.72339527 14.61031139 13.94829167 14.04503372\n",
            " 14.17737203 14.37740945 14.25247433 14.32112261 13.87377947 13.50626431\n",
            " 13.91082074 14.09314229 14.50665574 14.52058631 14.9384902  14.41214684\n",
            " 13.83138391 13.63398868 14.18707411 14.48845503 14.28050165 13.67624849\n",
            " 13.77676973 13.69221234 14.23290424 13.72119988 15.18770599 14.63793007\n",
            " 14.42527613 15.06369162 13.94302388 13.63877338 13.76632031 13.95874473\n",
            " 13.89432174 14.19394699 15.1372664  14.03384255 14.44358574 14.01272073\n",
            " 13.62192581 14.05924074 14.29422613 13.981025   14.0794121  14.14337442\n",
            " 14.8190793  14.26403516 14.04344263 14.3864901  14.18569385 13.75363515\n",
            " 14.59023773 14.03062194 14.09162599 14.46051736 14.66822231 13.72558585\n",
            " 13.7343005  13.75576055 14.40551698 14.27420043 13.82743913 13.98778178\n",
            " 13.49254667 14.41873303 13.89985171 13.8411783  14.20349035 14.09918461\n",
            " 14.53529967 13.9552725  14.33668247 14.2102517  14.57725053 14.55171723\n",
            " 15.00882678 14.04025283 13.36922346 13.96220494 14.01107734 14.25118151\n",
            " 14.02252473 13.85280634 14.36824558 14.84441543 13.47583319 13.93240431\n",
            " 13.85857005 14.1505532  13.83531319 13.83922708 14.09010739 13.5116991\n",
            " 14.47406629 14.43823527 13.5619078  13.79326495 14.43177669 15.04456614\n",
            " 15.07963729 14.65966061 14.80802132 15.04222285 14.20620038 13.99783211\n",
            " 14.45736444 14.21830544 14.3102068  14.07015278 13.94653882 15.0762417\n",
            " 14.11857373 14.33072653 15.11078552 14.76329996 14.95270233 13.86048392\n",
            " 14.44890773 14.16757489 14.48231376 13.21037425 13.31793016 13.48978042\n",
            " 13.50079981 14.02414942 14.13759406 14.21964144 14.02900773 13.90535126\n",
            " 14.13178009 14.12152359 13.59236701 14.01763474 15.00579004 13.4357132\n",
            " 14.27293541 13.48700649 13.22130333 13.46453364 13.49530529 13.40904495\n",
            " 13.97932864 14.20077296 14.61930426 14.12004975 14.35434038 13.78091911\n",
            " 13.11433121 14.91412285 13.41801362 14.60305841 14.58376521 13.45310494\n",
            " 13.81750856 14.52157396 15.0631174  13.80747839 13.19561384 14.43285603\n",
            " 13.7123698  13.87754595 13.42394836 14.54015641 13.9234677  14.08247959\n",
            " 14.40107253 14.41654245 14.06549076 13.82149263 13.39999511 13.57978822\n",
            " 14.71972871 14.29546452 13.72777164 13.84312572 15.5874074  14.80579497\n",
            " 14.33905495 14.27166878 13.71899966 14.02739092 13.90717775 14.03223354\n",
            " 13.18815112 13.5089854  14.63705095 14.49049377 14.01599942 14.4478456\n",
            " 13.8812983  13.97080344 14.31870715 14.12446477 13.96393056 14.21562806\n",
            " 13.71458464 13.07736601 13.71679459 13.8566525  14.26019638 14.14912156\n",
            " 13.65534181 14.49759679 14.44678233 13.92167075 14.26658618 14.58283714\n",
            " 13.74078701 13.95353186 14.0855377  13.79121787 13.86999874 13.86810301\n",
            " 14.45946749 13.42984808 14.24077829 13.64115717 14.28551419 13.78711108\n",
            " 14.89051298 14.39436859 13.59983902 14.2929862  14.05295141 14.08400981\n",
            " 14.38309452 14.68764039 14.10668652 15.15680755 14.3004028  14.38422766\n",
            " 14.61481793 14.29793671 13.81150254 13.54107371 14.59666862 14.30163357\n",
            " 13.81950258 13.56961002 13.67164019 13.51979631 13.55154501 14.26531148\n",
            " 14.47922893 13.89061803 13.62918098 14.39660823 14.49455881 14.05767212\n",
            " 14.1346913  14.30531681 14.06860119 14.59115896 14.11413257 13.45883561\n",
            " 14.70175437 13.21767356 13.87942388 14.31507299 14.29174474 14.60214808\n",
            " 14.27924457 13.60725562 14.18015367 14.19668297 13.2498767  14.00613092\n",
            " 14.60759769 14.05137288 15.12276171 14.44996874 14.16475799 13.59735455\n",
            " 14.07170196 13.41204345 13.78916658 13.61705962 14.24208463 15.00761319\n",
            " 13.34069537 13.6785447  14.36939567 13.37855478 14.15483586 13.75788145\n",
            " 13.46737052 14.48538911 13.48143545 13.58986388 14.32953107 14.28925717\n",
            " 14.74452006 13.43863291 13.30468493 13.78298737 14.50965724 13.77884657\n",
            " 13.96565322 14.67077659 14.7508193  14.30409057 14.57069313 13.5644818\n",
            " 14.173185   14.34260315 13.35980423 14.19257619 14.45631126 13.23925713\n",
            " 14.17038388 13.69897674 13.70346105 13.86239414 14.55458667 13.69672702\n",
            " 14.40994177 14.12886038 13.91263727 14.9462673  13.33100224 14.3437831\n",
            " 14.26913071 14.00778245 14.35667138 14.09767745 13.60971564 13.78505135\n",
            " 14.88983015 14.13904228 14.27040055 14.22762021 14.75317132 13.30801272\n",
            " 13.16924696 14.53139723 14.05452746 14.52354635 13.142166   14.51959768\n",
            " 14.0946563  13.71015004 14.24988701 13.40302083 14.32232816 13.60478953\n",
            " 13.45022724 14.24469219 13.96047633 13.45597438 13.95701012 13.64827464\n",
            " 14.06704718 13.65299163 14.82273828 14.98489192 13.66235938 13.61216963\n",
            " 14.22629483 14.15341035 13.20302128 13.28107507 13.55932715 13.70569569\n",
            " 14.55839983 15.10859254 14.97176263 14.36131715 13.3534751  14.19941149\n",
            " 14.56125019 13.70792535 13.88876102 14.5036452  14.22363878 13.18439877\n",
            " 13.76841895 14.86072207 13.66468767 15.03928599 13.98609686 13.81350856\n",
            " 14.19120351 13.26038468 13.52248088 13.60231734 13.36295384 14.18982894\n",
            " 14.64841968 14.01436142 13.27078338 13.89616846 15.05098203 14.21428668\n",
            " 14.55935085 14.35083365 13.73212895 14.13614373 14.88572337 14.30286283\n",
            " 15.08189462 13.35029545 15.21126008 14.37626855 14.60396792 13.61949567\n",
            " 14.20484628 13.64590777 15.18058128 14.52747949 15.19074397 14.37854905\n",
            " 14.16334655 13.38779984 13.41503299 13.68540187 14.57257106 15.19377275\n",
            " 13.39391607 14.56219851 13.91987057 13.67394699 13.94478289 13.66002566\n",
            " 14.66052009 14.67247582 14.72376912 14.3259361  14.66651582 14.33430435\n",
            " 14.1605177  14.00281966 14.23947025 14.53821654 13.83727205 13.93418209\n",
            " 13.74293987 15.04398083 14.22230811 13.32448756 14.24859083 14.31385866\n",
            " 14.02089739 14.33786942 13.65768647 13.9090009  13.86430072 14.21294349\n",
            " 14.38196009 14.32713586 14.42091882 14.38082437 14.37054444 14.8205445\n",
            " 14.28426341 13.8924716  14.31264285 14.66137883 14.24729297 13.5670492\n",
            " 14.27546385 14.72215491 14.24599343 14.67840051 13.74508809 14.88297612\n",
            " 14.85295641 13.92705193 14.50765724 13.80546022 14.23553582 14.07324875\n",
            " 13.70122141 14.54209251 14.23816049 13.86620367 14.18845247 13.84894533\n",
            " 13.95178818 14.4626138  13.21403057 14.39884287 14.48641213 14.60940764\n",
            " 14.50263967 14.29670138 14.00943125 14.50565323 14.53432549 13.79530785\n",
            " 14.36015773 13.82546089 14.66223683 13.72995267 13.10216067 14.59575245\n",
            " 13.87189089 14.1829276  13.23211424 14.63087537 14.55075891 13.59486389\n",
            " 14.41982652 14.15198279 13.36609356 13.85473127 14.09616802 14.44251794\n",
            " 13.89801178 14.02577148 13.75150523 14.63264372 14.23422089 14.87884103\n",
            " 13.76421726 14.78173366 14.62821697 13.93772819 13.91626046 14.32353225\n",
            " 14.25505498 13.69447223 14.77025248 14.70092963 15.03869758 14.41544536\n",
            " 14.16193313 13.90168825 14.10369251 12.83734442 14.41104491 14.19531592\n",
            " 14.23158585 13.40603743 14.22496769 13.32121424 14.45208739 15.09588869\n",
            " 15.0304233  14.041849   14.44144899 14.41434706 14.07787482 14.46156613\n",
            " 14.47095587 14.54787845 14.6501573  13.99114313 14.34023909 14.56975284\n",
            " 14.33192056 14.46366037 14.20213258] \n",
            "\n",
            "Unnamed: 0             int64\n",
            "Make                  object\n",
            "Make_Year              int64\n",
            "Color                 object\n",
            "Body_Type             object\n",
            "Mileage_Run            int64\n",
            "No_of_Owners          object\n",
            "Seating_Capacity       int64\n",
            "Fuel_Type             object\n",
            "Transmission          object\n",
            "Transmission_Type     object\n",
            "Price                  int64\n",
            "price_log            float64\n",
            "dtype: object\n",
            "2.750062975717002\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d",
      "metadata": {
        "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d"
      },
      "source": [
        "**Q2.** The is a question about regression using decision trees and linear models. The data include wages at data science-y jobs, including\n",
        "\n",
        "  - `Rating`: Company worker happiness score\n",
        "  - `Size`: Number of employees\n",
        "  - `Sector`: Part of the economy\n",
        "  - `avg_salary`: Average wage\n",
        "  - `job_state`: Location of work\n",
        "\n",
        "  1. Load the `wages_hw.csv` file. Split the sample into an ~80% training set and a ~20% test set. Do any necessary cleaning, including outliers and missings.\n",
        "  2. Use a linear model to regress `avg_salary` on `Sector`. Which sectors have the highest predicted wages? What is the $R^2$ and `RMSE` on the test set?\n",
        "  3. Make a scatterplot of `avg_salary` and `Rating`. Is there an obvious visual relationship between the two variables? Regress `avg_salary` on `Rating` as a numeric variable: Do higher ratings predict higher or lower wages? Convert `Rating` to a one-hot encoded variable, with a category for each rating. Run a regression of `avg_salary` on the categorical version. How do your results change? Explain. Which version has a higher $R^2$ and lower `RMSE`?\n",
        "  4. Now interact `Sector` with the categorical version of `Rating`, so your regressors are a (Sector, Rating) pair; this is a programming puzzle you'll have to think about, but using the `.PolynomialFeatures()` function on the one-hot encoded categorical variables is one option, and another is pre-processing a new variable that interacts `Sector` and `Rating` and then one-hot encoding the result. Regress `avg_salary` on the (Sector, Rating) pairs. How does the $R^2$ and `RMSE` on the test set compare to part 2? Interpret the coefficients; which sector-rating pairs have the highest wages?\n",
        "  5. Run a linear regression of `avg_salary` on all the variables. What is the $R^2$ on the test set? How does it compare to your simpler models in 2--4?\n",
        "  6. Build a decision tree by regressing `avg_salary` on `Sector`, `Rating`, and the (Sector, Rating) pairs. What are the $R^2$ and `RMSE` of your models on the test set? How do your answers compare to parts 2, 3, and 4?\n",
        "  7. Build a decision tree by regressing `avg_salary` on all the other variables. What is the $R^2$ and `RMSE` on the test set?\n",
        "  8. Build a linear regression or decision tree using the available variables based on your own judgment. What degrees of freedom are you giving the model to predict variation in wages across company and location attributes? What is the $R^2$ and `RMSE` of your model? How does it compare to the previous ones in the question? Why does yours perform better or worse on the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "409519b9-e803-4a95-aded-d6eabf6bc526",
      "metadata": {
        "id": "409519b9-e803-4a95-aded-d6eabf6bc526"
      },
      "source": [
        "**Q3.** This a question purely on categorical prediction. The data for this happen to be gathered in 1987 in Indonesia, and concern contraceptive method choice. The questions and data-gathering assumptions reflect the culture and attitudes of that time and place, but provide a good example of a categorical prediction problem on an important topic (family planning and maternal health The variables in the data are:\n",
        "\n",
        "    - Wife's age (numerical)\n",
        "    - Wife's education (categorical) 1=low, 2, 3, 4=high\n",
        "    - Husband's education (categorical) 1=low, 2, 3, 4=high\n",
        "    - Number of children ever born (numerical)\n",
        "    - Wife's religion (binary) 0=Non-Islam, 1=Islam\n",
        "    - Wife's now working? (binary) 0=Yes, 1=No\n",
        "    - Husband's occupation (categorical) 1, 2, 3, 4\n",
        "    - Standard-of-living index (categorical) 1=low, 2, 3, 4=high\n",
        "    - Media exposure (binary) 0=Good, 1=Not good\n",
        "    - Contraceptive method used (class attribute) 1=No-use, 2=Long-term, 3=Short-termhort-term\n",
        "\n",
        "  1. Load the `contraceptiveMethodChoice.csv` data. Tabulate the `method` variable (i.e. `.value_counts()`). 1 corresponds to `No Contraception`, 3 corresponds to `Short Term` (e.g. condoms, birth control pills), and 2 corresponds to `Long Term` (e.g. IUD, sterilization). Cross tabulate `method` and `numberChildren`. Do couples that use birth control tend to have more children than those who don't?\n",
        "  2. Split the sample into ~80% training data and ~20% testing data.\n",
        "  3. We are now going to make a mistake. Train a regression tree to predict the contraceptive method using the other variables in the data, not a classification tree. Look at the terminal nodes in the tree: What values do they take? Does that make sense? Explain clearly what has gone wrong here.\n",
        "  4. Instead of regression, use a classification tree to predict contraceptive method using the other variables in the data. How does it look different from the previous tree? What variables does the algorithm use? In broad terms, which groups of people are most likely to use each method of contraception?\n",
        "  5. Compute a confusion matrix for your classification tree on the test set (Hint: There are now three categories instead of two, so the cross tabulation will be a $3 \\times 3$ matrix instead of $2 \\times 2$.). Compute the Accuracy of your model overall, and the Accuracy for predicting each contraceptive method.\n",
        "  7. Why can't you use a linear probability model to do this exercise? Explain clearly in words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a",
      "metadata": {
        "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a"
      },
      "source": [
        "**Q4.** This is a question where we use regression and regression trees. The outcome is whether a defendant is held pre-trial in the Virginia justice system. We would like to understand how that outcome is predicted by characteristics of the defendant, particularly race. Let's be very careful/clear: We aren't saying anyone *should* be held without bond or asserting that people with different demographic variables *should* be more likely to be held, but instead trying to predict whether people with different characteristics *are empirically more likely* to be held without bond, given the available information. This is the first step we would take in investigating whether a system is fair, or how large the disparities are: Does it treat people with similar observable characteristics similarly, or not? We are going to look at a common question: Are Black defendants treated differently from white or Asian ones? (There are Native American defendants, but there are 11 in total, which is such a small number of observations that is difficult to clearly say anything about how this group is treated relative to the others.)\n",
        "\n",
        "The variables in the data are:\n",
        "\n",
        "  - `held_wo_bail`: Whether a defendant is held without bail before trial (Boolean logical)\n",
        "  - `race`, `sex`: Categorical demographic variables\n",
        "  - `is_poor`: Whether the defendant is classified as indigent\n",
        "  - `prior_F`, `prior_M`: The number of prior felony and misdemeanor arrests\n",
        "  - `case_type`: A categorical variable indicating a misdemeanor `M` or felony `F` or infraction `I` or special case `S`\n",
        "  - `age`: Defendant's age\n",
        "  - `bond`, `bond_NA`, `bond_type`: The amount of any bond, whether it is missing, and the type\n",
        "  - `sentence`, `sentence_NA`, `sentence_type`: The length of any sentence, whether it is missing, and the type\n",
        "\n",
        "1. Load the `pretrial_data.csv` data. Notice that there are `nan`s, but the data are relatively clean. Because there are `.nan`s among variables you won't use, you'll want to narrow down your analysis to the relevant variables before dropping or imputing missing values.\n",
        "2. Create a dummy variable indicating that the defendant is Black.\n",
        "3. Regress `held` on `Black`. What is the slope coefficient Interpret the coefficient on the Black dummy variable: How much more likely is a black person to be held without bail? What is the $R^2$ of the model?\n",
        "4. Before doing this question, please think for a few minutes about how to make the process of running these regressions as efficient as possible, before jumping into writing code. Repeat part 2, for the following specifications, keeping track of the coefficient on the Black dummy variable each time:\n",
        "      - `held` on `Black` and `sex`\n",
        "      - `held` on `Black` and `sex` and `is_poor`\n",
        "      - `held` on `Black` and `sex` and `is_poor` and `prior_F`\n",
        "      - `held` on `Black` and `sex` and `is_poor` and `prior_F` and `case_type`\n",
        "What happens to the coefficient on the Black dummy variable as you include more regressors/features/controls in the regression? Explain your findings.\n",
        "5. Suppose we don't want to see just `Black` and `sex`, but `Black` interacted with `sex`: Are Black men and Black women treated systemically differently from the rest of the population? Implement this in a regression, and explain your findings.\n",
        "6. Imagine someone argued we should use these kinds of models to help a judge or magistrate make bail decisions (you could obviously go back and make this kind of model for the bond and sentence variables, then deploy it on new cases to predict what their bond and sentence values would be). What concerns would you have? Do you think society should be using data-driven and automated tools like that? Explain your concerns clearly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0bedb79-b3d9-4db3-9b30-b92c9b618cec",
      "metadata": {
        "id": "d0bedb79-b3d9-4db3-9b30-b92c9b618cec"
      },
      "source": [
        "**Q5.** This is a math question to review the derivation of the OLS estimator (but only if you are into that kind of thing!). We are going to do it slightly differently from what we did in class, though. We will use a linear predictor and minimize the Sum of Squared Errors, just as in class. But, we are going to de-mean $X$ first, creating another variable $z_i = x_i - \\bar{x}$ where\n",
        "$$\n",
        "\\bar{x} = \\dfrac{1}{N} \\sum_{i=1}^N x_i,\n",
        "$$\n",
        "so the model is $\\hat{y}_i = a + b z_i$ and the `SSE` is\n",
        "$$\n",
        "\\text{SSE}(a,b) = \\sum_{i=1}^N (y_i - a - bz_i)^2.\n",
        "$$\n",
        "\n",
        "  1. Take partial derivatives of the `SSE` with respect to $a$ and $b$. You should get\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\sum_{i=1}^N -2(y_i - a- bz_i) &=& 0 \\\\\n",
        "\\sum_{i=1}^N -2(y_i - a - bz_i)z_i &=& 0.\n",
        "\\end{eqnarray*}\n",
        "\n",
        "  2. Solve for the solutions to the above equations. Big hint: $\\bar{z} = 0$, since we subtracted the mean of $x$ from $x$ to get $z$. You should get\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "a^* &=& \\bar{y} \\\\\n",
        "b^* &=& \\dfrac{\\sum_{i=1}^N(y_i - \\bar{y})z_i}{\\sum_{i=1}^N z_i^2}.\n",
        "\\end{eqnarray*}\n",
        "\n",
        "  3. Substitute $z_i = x_i - \\bar{x}$ back into the above equations. You should get\n",
        "  \n",
        "\\begin{eqnarray*}\n",
        "a^* &=& \\bar{y} \\\\\n",
        "b^* &=& \\dfrac{\\sum_{i=1}^N(y_i - \\bar{y})(x_i-\\bar{x})}{\\sum_{i=1}^N (x_i-\\bar{x})^2},\n",
        "\\end{eqnarray*}\n",
        "\n",
        "which can be written in terms of sample covariance and sample variance as:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "a^* &=& \\bar{y} \\\\\n",
        "b^* &=& \\dfrac{\\text{cov}(x,y)}{\\text{var}(x)}.\n",
        "\\end{eqnarray*}\n",
        "\n",
        "This is typically the preferred way of expressing the OLS coefficients.\n",
        "\n",
        "4. When will $b^*$ be large or small, depending on the relationship between $x$ and $y$ and the amount of \"noise\"/variance in $x$? What does $a^*$ represent?\n",
        "5. Suppose you have measurement error in $x$ which artificially inflates its variance (e.g. bad data cleaning). What happens to the $b^*$ coefficient? How will affect your ability to predict? (This phenomenon is called **attenuation**.)\n",
        "6. Let's return to the question of *outliers*. With your formula for the OLS coefficients $(a^*,b^*)$, explain what happens if you significantly increase a single value of the outcome/target/response variable $y_i$ or one of the predictor/explanatory/covariate variables $x_i$. If values for some extreme observations are exerting significant influence over the regression coefficients, will the model perform well on for more average observations?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}